{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type >>>>> 3\n",
    "    #1 PorterStemmer\n",
    "    #2 RegexpStemmer\n",
    "    #3 Snowball Stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification Problem\n",
    "## Comments of product is a positive review or negative review\n",
    "## Reviews----> eating, eat,eaten [going,gone,goes]--->go\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PorterStemmer\n",
    "Developed by: Martin Porter (1980)\n",
    "\n",
    "Approach: Uses a set of predefined rules to remove suffixes from words.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Simple and efficient.\n",
    "\n",
    "Works well for general text processing.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Can be too aggressive, sometimes removing too much of the word.\n",
    "\n",
    "Does not always produce meaningful stems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating------------>eat\n",
      "eats------------>eat\n",
      "eaten------------>eaten\n",
      "writing------------>write\n",
      "writes------------>write\n",
      "programming------------>program\n",
      "programs------------>program\n",
      "history------------>histori\n",
      "finally------------>final\n",
      "finalized------------>final\n"
     ]
    }
   ],
   "source": [
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]\n",
    "\n",
    "for word in words: \n",
    "    print(word +\"------------>\"+stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('congratulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pankaj'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('pankaj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RegexpStemmer\n",
    "Approach: Uses regular expressions to define how words should be stemmed.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Highly customizable.\n",
    "\n",
    "Allows fine-tuned control over stemming behavior.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Requires manual rule definition.\n",
    "\n",
    "Less effective for general cases without careful configuration.\n",
    "\n",
    "NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression. Let us see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "stemmer=RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'st'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('stable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'snake'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('snakes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Snowball Stemmer (Also called Porter2 Stemmer)\n",
    " It is a stemming algorithm which is also known as the Porter2 stemming algorithm as it is a better version of the Porter Stemmer since some issues of it were fixed in this stemmer.\n",
    "Developed by: Martin Porter (an improvement over PorterStemmer)\n",
    "\n",
    "Approach: More advanced and supports multiple languages.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "More accurate and less aggressive than PorterStemmer.\n",
    "\n",
    "Can stem words in different languages (English, Spanish, French, etc.).\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Slightly slower than PorterStemmer.\n",
    "\n",
    "Can still remove too much from some words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating------------>eat\n",
      "eats------------>eat\n",
      "eaten------------>eaten\n",
      "writing------------>write\n",
      "writes------------>write\n",
      "programming------------>program\n",
      "programs------------>program\n",
      "history------------>histori\n",
      "finally------------>final\n",
      "finalized------------>final\n"
     ]
    }
   ],
   "source": [
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]\n",
    "\n",
    "for word in words: \n",
    "    print(word +\"------------>\"+stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
